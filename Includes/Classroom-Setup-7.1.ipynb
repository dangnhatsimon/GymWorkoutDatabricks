{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cae25252-720f-44d1-a7d8-e7dd8a6a4241",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./_databricks-academy-helper $lesson=\"7.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e15bcc1e-6fd2-43b5-8fbb-48ff03878250",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./_utility-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebc522d2-5e0b-4047-ae87-41b73577c78c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DA.paths.cdc_stream = f\"{DA.paths.working_dir}/streams/cdc\"\n",
    "\n",
    "class CdcStreamingFactory:\n",
    "    def __init__(self, max_batch=3):\n",
    "        self.batch = 1\n",
    "        self.max_batch = max_batch\n",
    "        dbutils.fs.mkdirs(DA.paths.cdc_stream)\n",
    "        \n",
    "    def load(self):\n",
    "        import time\n",
    "        from pyspark.sql import functions as F\n",
    "        \n",
    "        start = int(time.time())\n",
    "        raw_df = spark.read.load(f\"{DA.hidden.datasets}/pii/raw\")\n",
    "        \n",
    "        if self.batch > self.max_batch:\n",
    "            print(\"Data source exhausted\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"Loading batch #{self.batch} to the cdc stream\", end=\"...\")\n",
    "            df = (raw_df.filter(F.col(\"batch\") == self.batch)\n",
    "                        .select('mrn','dob','sex','gender','first_name','last_name','street_address','zip','city','state','updated'))\n",
    "            df.write.mode(\"append\").format(\"json\").save(DA.paths.cdc_stream)\n",
    "            total = df.count()\n",
    "            self.batch += 1\n",
    "            print(f\"({int(time.time())-start} seconds, {total:,} records)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "697c23d7-2aeb-46be-878e-c6cfc0ffdd30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DA.cleanup()\n",
    "DA.init()\n",
    "\n",
    "DA.cdc_stream = CdcStreamingFactory()\n",
    "DA.paths.silver_source = f\"{DA.hidden.datasets}/pii/silver\"\n",
    "\n",
    "DA.conclude_setup()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Classroom-Setup-7.1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}