{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d643fce-d082-4059-8954-0c48e97f81e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./_databricks-academy-helper $lesson=\"8.4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e70be5ec-d678-4e76-a865-78b5b424f0b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./_utility-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a0c3c02-c65a-4b35-9a49-65aba5970003",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_bronze_dev_table():\n",
    "    import time\n",
    "    \n",
    "    start = int(time.time())\n",
    "    print(f\"Creating bronze_dev\", end=\"...\")\n",
    "\n",
    "    spark.sql(f\"\"\"\n",
    "      CREATE TABLE bronze_dev\n",
    "      SHALLOW CLONE delta.`{DA.hidden.datasets}/bronze`\n",
    "      LOCATION '{DA.paths.user_db}/bronze_dev'\n",
    "    \"\"\")\n",
    "\n",
    "    total = spark.read.table(\"bronze_dev\").count()\n",
    "    assert total == 10841978, f\"Expected 10,841,978 records, found {total:,} in bronze_dev\"    \n",
    "    print(f\"({int(time.time())-start} seconds / {total:,} records)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a4e3e3d-b13b-4d6b-bfdd-5b1149628304",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class BronzeDataStreamFactory:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def load_batch(self, df):\n",
    "        df.drop(\"arrival\").write.mode(\"append\").format(\"json\").save(DA.paths.producer_30m)\n",
    "        return df.count()\n",
    "    \n",
    "    def load(self, from_batch=0, batch_delay=5):\n",
    "        import time\n",
    "        from pyspark.sql import functions as F\n",
    "\n",
    "        total = 0\n",
    "        batch = from_batch\n",
    "        producer_df = spark.read.load(f\"{DA.hidden.datasets}/kafka-30min\")\n",
    "        arrival_max, arrival_min = producer_df.select(F.max(\"arrival\"), F.min(\"arrival\")).collect()[0]\n",
    "\n",
    "        if batch_delay == 0:\n",
    "            start = int(time.time()*1000)\n",
    "            print(\"Loading all batches to producer_30m\", end=\"...\")\n",
    "            total = self.load_batch(producer_df.filter(F.col(\"arrival\") >= arrival_min+batch))\n",
    "            print(f\"({int(time.time()*1000)-start:,} ms, {total:,} records)\")\n",
    "            \n",
    "        else:\n",
    "            while arrival_min+batch < arrival_max+1:\n",
    "                start = int(time.time()*1000)\n",
    "                print(f\"Loading batch #{batch+1} to producer_30m\", end=\"...\")\n",
    "                total += self.load_batch(producer_df.filter(F.col(\"arrival\") == arrival_min+batch))\n",
    "                print(f\"({int(time.time()*1000)-start} ms, {total:,} records)\")\n",
    "                batch += 1    \n",
    "                time.sleep(batch_delay)\n",
    "\n",
    "DA.paths.producer_30m = f\"{DA.paths.working_dir}/producer_30m\"            \n",
    "DA.bronze_data_stream = BronzeDataStreamFactory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ef9cf91-707d-47f0-81b1-8c79689bba7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DA.cleanup()\n",
    "DA.init()\n",
    "\n",
    "create_date_lookup()\n",
    "create_bronze_dev_table()\n",
    "\n",
    "DA.conclude_setup()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Classroom-Setup-8.4.1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}