{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb9b4961-8a30-4cd2-853e-00e063248e1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65689e78-e4c0-49dd-86e3-34bc4bb8ec96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Type 2 Slowly Changing Data\n",
    "\n",
    "In this notebook, we'll create a silver table that contains the information we'll need to link workouts back to our heart rate recordings.\n",
    "\n",
    "We'll use a Type 2 table to record this data, encoding the start and end times for each session. \n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/ade/ADE_arch_completed_workouts.png\" width=\"60%\" />\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this lesson, students will be able to:\n",
    "- Describe how Slowly Changing Dimension tables can be implemented in the Lakehouse\n",
    "- Use custom logic to implement a SCD Type 2 table with batch overwrite logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17489e52-36f0-4f3b-a8cb-0d7643e643e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Setup\n",
    "Set up path and checkpoint variables (these will be used later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24569c1d-9bb0-4e89-aa2b-82324700926c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../Includes/Classroom-Setup-4.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94f88cb7-8721-44bb-a0e5-253622288478",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Review workouts_silver Table\n",
    "Several helper functions was defined to land and propagate a batch of data to the **`workouts_silver`** table.\n",
    "\n",
    "This table is created by \n",
    "* Starting a stream against the **`bronze`** table\n",
    "* Filtering all records by **`topic = 'workout'`**\n",
    "* Deduping the data \n",
    "* Merging non-matching records into **`owrkouts_silver`**\n",
    "\n",
    "...roughly the same strategy we used earlier to create the **`heart_rate_silver`** table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24df2472-480c-467e-9fd3-1fd01130b903",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DA.daily_stream.load()       # Load another day's data\n",
    "DA.process_bronze()          # Update the bronze table\n",
    "DA.process_workouts_silver() # Update the workouts_silver table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eaa8e5c3-816c-4d8a-bf90-6a0aaaa50d35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Review the **`workouts_silver`** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b62f4449-f62e-4a81-a8c3-f1dc2ac553c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "workout_df = spark.read.table(\"workouts_silver\")\n",
    "display(workout_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c4e2d911-cdfe-4e2a-93a8-8deda031d4e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "For this data, the **`user_id`** and **`session_id`** form a composite key. \n",
    "\n",
    "Each pair should eventually have 2 records present, marking the \"start\" and \"stop\" action for each workout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8858c752-6814-4a59-8a72-857ed33c771c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "aggregate_df = workout_df.groupby(\"user_id\", \"session_id\").count()\n",
    "display(aggregate_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b3bf6c4-18d4-43a9-ad77-46dac7105e38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Because we'll be triggering a shuffle in this notebook, we'll be explicit about how many partitions we want at the end of our shuffle.\n",
    "\n",
    "As before, we can use the current level of parallelism (max number of cores) as our upper bound for shuffle partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43be1a42-b0cc-4984-b4e7-d2124a250ba6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Executor cores: {sc.defaultParallelism}\")\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", sc.defaultParallelism)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92a6bae8-8cea-4bc9-949c-05045ea48160",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create Completed Workouts Table\n",
    "\n",
    "The query below matches our start and stop actions, capturing the time for each action. The **`in_progress`** field indicates whether or not a given workout session is ongoing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4a7894f-3cdb-40d0-89a6-9b2ae96dcc43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_completed_workouts():\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE OR REPLACE TABLE completed_workouts \n",
    "        AS (\n",
    "          SELECT a.user_id, a.workout_id, a.session_id, a.start_time start_time, b.end_time end_time, a.in_progress AND (b.in_progress IS NULL) in_progress\n",
    "          FROM (\n",
    "            SELECT user_id, workout_id, session_id, time start_time, null end_time, true in_progress\n",
    "            FROM workouts_silver\n",
    "            WHERE action = \"start\") a\n",
    "          LEFT JOIN (\n",
    "            SELECT user_id, workout_id, session_id, null start_time, time end_time, false in_progress\n",
    "            FROM workouts_silver\n",
    "            WHERE action = \"stop\") b\n",
    "          ON a.user_id = b.user_id AND a.session_id = b.session_id\n",
    "        )\n",
    "    \"\"\")\n",
    "    \n",
    "process_completed_workouts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79086768-6882-44b3-8178-69a4a23dbcea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "You can now perform a query directly on your **`completed_workouts`** table to check your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b536524-9820-4541-bd76-7c699999619f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "total = spark.table(\"completed_workouts\").count() # .sql(\"SELECT COUNT(*) FROM completed_workouts\") \n",
    "print(f\"{total:3} total\")\n",
    "\n",
    "total = spark.table(\"completed_workouts\").filter(\"in_progress=true\").count()\n",
    "print(f\"{total:3} where record is still awaiting end time\")\n",
    "\n",
    "total = spark.table(\"completed_workouts\").filter(\"end_time IS NOT NULL\").count()\n",
    "print(f\"{total:3} where end time has been recorded\")\n",
    "\n",
    "total = spark.table(\"completed_workouts\").filter(\"start_time IS NOT NULL\").count()\n",
    "print(f\"{total:3} where end time arrived after start time\")\n",
    "\n",
    "total = spark.table(\"completed_workouts\").filter(\"in_progress=true AND end_time IS NULL\").count()\n",
    "print(f\"{total:3} where they are in_progress AND have an end_time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9f4b827-1955-4b5c-864e-e2be13436599",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Use the functions below to propagate another batch of records through the pipeline to this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5290ec9c-74fa-4523-9882-dfb6a6cd702a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DA.daily_stream.load()       # Load another day's data\n",
    "DA.process_bronze()          # Update the bronze table\n",
    "DA.process_workouts_silver() # Update the workouts_silver table\n",
    "\n",
    "process_completed_workouts() # Update the completed_workouts table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "604fcd01-5ec8-48e4-b850-9ddc6adc6828",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT COUNT(*) \n",
    "AS total \n",
    "FROM completed_workouts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d76edf17-a1c3-4e9b-bf47-f117e64d4989",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Run the following cell to delete the tables and files associated with this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "612a2fbf-b6c1-4d06-87d2-6b55a5f4e14e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DA.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9259103-3942-4194-94f6-81c686703bfd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2022 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/>\n",
    "<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "ADE 3.4 - Type 2 SCD",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}